{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# AI Service Deployment Notebook\nThis notebook contains steps and code to test, promote, and deploy an Agent as an AI Service.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Contents\nThis notebook contains the following parts:\n\n1. Setup\n2. Initialize all the variables needed by the AI Service\n3. Define the AI service function\n4. Deploy an AI Service\n5. Test the deployed AI Service\n\n## 1. Set up the environment\n\nBefore you can run this notebook, you must perform the following setup tasks:", "metadata": {}}, {"cell_type": "markdown", "source": "### Connection to WML\nThis cell defines the credentials required to work with watsonx API for both the execution in the project, \nas well as the deployment and runtime execution of the function.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n", "metadata": {}}, {"cell_type": "code", "source": "import os\nfrom ibm_watsonx_ai import APIClient, Credentials\nimport getpass\n\ncredentials = Credentials(\n    url=\"https://us-south.ml.cloud.ibm.com\",\n    api_key=getpass.getpass(\"Please enter your api key (hit enter): \")\n)\n\n", "metadata": {"id": "cb60bd70-1309-4a97-b740-db0954e9de32"}, "outputs": [{"output_type": "stream", "name": "stdin", "text": "Please enter your api key (hit enter):  \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}], "execution_count": 6}, {"cell_type": "code", "source": "client = APIClient(credentials)", "metadata": {"id": "f7526cb5-3286-4a1b-925b-64e4f8dc7cb4"}, "outputs": [], "execution_count": 7}, {"cell_type": "markdown", "source": "### Connecting to a space\nA space will be be used to host the promoted AI Service.\n", "metadata": {}}, {"cell_type": "code", "source": "space_id = \"a010725f-42bd-49a9-97f4-fabe8e6db923\"\nclient.set.default_space(space_id)\n", "metadata": {"id": "8c98e64c-da03-473b-a17f-ed97c8224819"}, "outputs": [{"execution_count": 8, "output_type": "execute_result", "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}], "execution_count": 8}, {"cell_type": "markdown", "source": "### Promote asset(s) to space\nWe will now promote assets we will need to stage in the space so that we can access their data from the AI service.\n", "metadata": {}}, {"cell_type": "code", "source": "source_project_id = \"88f6c166-dac8-4f9f-83ef-5a9d98110298\"\nvector_index_id = client.spaces.promote(\"d578adc5-dc1f-4e46-a45e-c4ad627b63d4\", source_project_id, space_id)\nprint(vector_index_id)\n", "metadata": {"id": "b436ca67-267a-4dd6-a3f2-0d3b8a8b1763"}, "outputs": [{"name": "stdout", "text": "8fe84aae-dd89-4a29-9fb1-d703a3084b2d\n", "output_type": "stream"}], "execution_count": 9}, {"cell_type": "markdown", "source": "## 2. Create the AI service function\nWe first need to define the AI service function\n\n### 2.1 Define the function", "metadata": {}}, {"cell_type": "code", "source": "params = {\n    \"space_id\": space_id,\n    \"vector_index_id\": vector_index_id\n}\n\ndef gen_ai_service(context, params = params, **custom):\n    # import dependencies\n    from langchain_ibm import ChatWatsonx\n    from ibm_watsonx_ai import APIClient\n    from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n    from langchain_core.messages import AIMessage, HumanMessage\n    from langgraph.checkpoint.memory import MemorySaver\n    from langgraph.prebuilt import create_react_agent\n    import json\n    import requests\n\n    model = \"ibm/granite-3-3-8b-instruct\"\n    \n    service_url = \"https://us-south.ml.cloud.ibm.com\"\n    # Get credentials token\n    credentials = {\n        \"url\": service_url,\n        \"token\": context.generate_token()\n    }\n\n    # Setup client\n    client = APIClient(credentials)\n    space_id = params.get(\"space_id\")\n    client.set.default_space(space_id)\n\n\n    vector_index_id = params.get(\"vector_index_id\")\n\n    def create_rag_tool(vector_index_id, api_client):\n        config = {\n            \"vectorIndexId\": vector_index_id,\n            \"spaceId\": space_id\n        }\n    \n        tool_description = \"Search information in documents to provide context to a user query. Useful when asked to ground the answer in specific knowledge about Career_Guidance_Professional\"\n        \n        return create_utility_agent_tool(\"RAGQuery\", config, api_client, tool_description=tool_description)\n    \n\n    def create_chat_model(watsonx_client):\n        parameters = {\n            \"frequency_penalty\": 0,\n            \"max_tokens\": 2000,\n            \"presence_penalty\": 0,\n            \"temperature\": 0,\n            \"top_p\": 1\n        }\n\n        chat_model = ChatWatsonx(\n            model_id=model,\n            url=service_url,\n            space_id=space_id,\n            params=parameters,\n            watsonx_client=watsonx_client,\n        )\n        return chat_model\n    \n    \n    def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n        from langchain_core.tools import StructuredTool\n        utility_agent_tool = Toolkit(\n            api_client=api_client\n        ).get_tool(tool_name)\n    \n        tool_description = utility_agent_tool.get(\"description\")\n    \n        if (kwargs.get(\"tool_description\")):\n            tool_description = kwargs.get(\"tool_description\")\n        elif (utility_agent_tool.get(\"agent_description\")):\n            tool_description = utility_agent_tool.get(\"agent_description\")\n        \n        tool_schema = utility_agent_tool.get(\"input_schema\")\n        if (tool_schema == None):\n            tool_schema = {\n                \"type\": \"object\",\n                \"additionalProperties\": False,\n                \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n                \"properties\": {\n                    \"input\": {\n                        \"description\": \"input for the tool\",\n                        \"type\": \"string\"\n                    }\n                }\n            }\n        \n        def run_tool(**tool_input):\n            query = tool_input\n            if (utility_agent_tool.get(\"input_schema\") == None):\n                query = tool_input.get(\"input\")\n    \n            results = utility_agent_tool.run(\n                input=query,\n                config=params\n            )\n            \n            return results.get(\"output\")\n        \n        return StructuredTool(\n            name=tool_name,\n            description = tool_description,\n            func=run_tool,\n            args_schema=tool_schema\n        )\n    \n    \n    def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n        from langchain_core.tools import StructuredTool\n        import ast\n    \n        def call_tool(**kwargs):\n            tree = ast.parse(tool_code, mode=\"exec\")\n            custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n            function_name = custom_tool_functions[0].name\n            compiled_code = compile(tree, 'custom_tool', 'exec')\n            namespace = tool_params if tool_params else {}\n            exec(compiled_code, namespace)\n            return namespace[function_name](**kwargs)\n            \n        tool = StructuredTool(\n            name=tool_name,\n            description = tool_description,\n            func=call_tool,\n            args_schema=tool_schema\n        )\n        return tool\n    \n    def create_custom_tools():\n        custom_tools = []\n    \n\n    def create_tools(inner_client, context):\n        tools = []\n        tools.append(create_rag_tool(vector_index_id, inner_client))\n        \n        config = None\n        tools.append(create_utility_agent_tool(\"GoogleSearch\", config, inner_client))\n        config = {\n        }\n        tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, inner_client))\n        config = {\n            \"maxResults\": 5\n        }\n        tools.append(create_utility_agent_tool(\"Wikipedia\", config, inner_client))\n        return tools\n    \n    def create_agent(model, tools, messages):\n        memory = MemorySaver()\n        instructions = \"\"\"# Notes\n- When a tool is required to answer the user's query, respond only with <|tool_call|> followed by a JSON list of tools used.\n- If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\nYou are an intelligent, autonomous career counselling agent designed to assist students in making informed career decisions.\n\nYour primary role is to:\n\nContinuously guide students based on their academic performance, interests, and evolving goals.\n\nAnalyze and suggest suitable career pathways aligned with real-time labor market trends and in-demand skills.\n\nProvide personalized suggestions for courses, certifications, internships, and higher education opportunities.\n\nAnswer student queries about careers, job roles, industries, and required skills.\n\nBe supportive, clear, non-judgmental, and encourage students to explore their potential.\n\nNever guess personal information. Only respond based on provided data or general knowledge.\n\nKeep responses concise, actionable, and student-friendly.\"\"\"\n        for message in messages:\n            if message[\"role\"] == \"system\":\n                instructions += message[\"content\"]\n        graph = create_react_agent(model, tools=tools, checkpointer=memory, state_modifier=instructions)\n        return graph\n    \n    def convert_messages(messages):\n        converted_messages = []\n        for message in messages:\n            if (message[\"role\"] == \"user\"):\n                converted_messages.append(HumanMessage(content=message[\"content\"]))\n            elif (message[\"role\"] == \"assistant\"):\n                converted_messages.append(AIMessage(content=message[\"content\"]))\n        return converted_messages\n\n    def generate(context):\n        payload = context.get_json()\n        messages = payload.get(\"messages\")\n        inner_credentials = {\n            \"url\": service_url,\n            \"token\": context.get_token()\n        }\n\n        inner_client = APIClient(inner_credentials)\n        model = create_chat_model(inner_client)\n        tools = create_tools(inner_client, context)\n        agent = create_agent(model, tools, messages)\n        \n        generated_response = agent.invoke(\n            { \"messages\": convert_messages(messages) },\n            { \"configurable\": { \"thread_id\": \"42\" } }\n        )\n\n        last_message = generated_response[\"messages\"][-1]\n        generated_response = last_message.content\n\n        execute_response = {\n            \"headers\": {\n                \"Content-Type\": \"application/json\"\n            },\n            \"body\": {\n                \"choices\": [{\n                    \"index\": 0,\n                    \"message\": {\n                       \"role\": \"assistant\",\n                       \"content\": generated_response\n                    }\n                }]\n            }\n        }\n\n        return execute_response\n\n    def generate_stream(context):\n        print(\"Generate stream\", flush=True)\n        payload = context.get_json()\n        headers = context.get_headers()\n        is_assistant = headers.get(\"X-Ai-Interface\") == \"assistant\"\n        messages = payload.get(\"messages\")\n        inner_credentials = {\n            \"url\": service_url,\n            \"token\": context.get_token()\n        }\n        inner_client = APIClient(inner_credentials)\n        model = create_chat_model(inner_client)\n        tools = create_tools(inner_client, context)\n        agent = create_agent(model, tools, messages)\n\n        response_stream = agent.stream(\n            { \"messages\": messages },\n            { \"configurable\": { \"thread_id\": \"42\" } },\n            stream_mode=[\"updates\", \"messages\"]\n        )\n\n        for chunk in response_stream:\n            chunk_type = chunk[0]\n            finish_reason = \"\"\n            usage = None\n            if (chunk_type == \"messages\"):\n                message_object = chunk[1][0]\n                if (message_object.type == \"AIMessageChunk\" and message_object.content != \"\"):\n                    message = {\n                        \"role\": \"assistant\",\n                        \"content\": message_object.content\n                    }\n                else:\n                    continue\n            elif (chunk_type == \"updates\"):\n                update = chunk[1]\n                if (\"agent\" in update):\n                    agent = update[\"agent\"]\n                    agent_result = agent[\"messages\"][0]\n                    if (agent_result.additional_kwargs):\n                        kwargs = agent[\"messages\"][0].additional_kwargs\n                        tool_call = kwargs[\"tool_calls\"][0]\n                        if (is_assistant):\n                            message = {\n                                \"role\": \"assistant\",\n                                \"step_details\": {\n                                    \"type\": \"tool_calls\",\n                                    \"tool_calls\": [\n                                        {\n                                            \"id\": tool_call[\"id\"],\n                                            \"name\": tool_call[\"function\"][\"name\"],\n                                            \"args\": tool_call[\"function\"][\"arguments\"]\n                                        }\n                                    ] \n                                }\n                            }\n                        else:\n                            message = {\n                                \"role\": \"assistant\",\n                                \"tool_calls\": [\n                                    {\n                                        \"id\": tool_call[\"id\"],\n                                        \"type\": \"function\",\n                                        \"function\": {\n                                            \"name\": tool_call[\"function\"][\"name\"],\n                                            \"arguments\": tool_call[\"function\"][\"arguments\"]\n                                        }\n                                    }\n                                ]\n                            }\n                    elif (agent_result.response_metadata):\n                        # Final update\n                        message = {\n                            \"role\": \"assistant\",\n                            \"content\": agent_result.content\n                        }\n                        finish_reason = agent_result.response_metadata[\"finish_reason\"]\n                        if (finish_reason): \n                            message[\"content\"] = \"\"\n\n                        usage = {\n                            \"completion_tokens\": agent_result.usage_metadata[\"output_tokens\"],\n                            \"prompt_tokens\": agent_result.usage_metadata[\"input_tokens\"],\n                            \"total_tokens\": agent_result.usage_metadata[\"total_tokens\"]\n                        }\n                elif (\"tools\" in update):\n                    tools = update[\"tools\"]\n                    tool_result = tools[\"messages\"][0]\n                    if (is_assistant):\n                        message = {\n                            \"role\": \"assistant\",\n                            \"step_details\": {\n                                \"type\": \"tool_response\",\n                                \"id\": tool_result.id,\n                                \"tool_call_id\": tool_result.tool_call_id,\n                                \"name\": tool_result.name,\n                                \"content\": tool_result.content\n                            }\n                        }\n                    else:\n                        message = {\n                            \"role\": \"tool\",\n                            \"id\": tool_result.id,\n                            \"tool_call_id\": tool_result.tool_call_id,\n                            \"name\": tool_result.name,\n                            \"content\": tool_result.content\n                        }\n                else:\n                    continue\n\n            chunk_response = {\n                \"choices\": [{\n                    \"index\": 0,\n                    \"delta\": message\n                }]\n            }\n            if (finish_reason):\n                chunk_response[\"choices\"][0][\"finish_reason\"] = finish_reason\n            if (usage):\n                chunk_response[\"usage\"] = usage\n            yield chunk_response\n\n    return generate, generate_stream\n", "metadata": {"id": "b4667ad8-0160-46cb-8831-b63b7094a622"}, "outputs": [], "execution_count": 10}, {"cell_type": "markdown", "source": "### 2.2 Test locally", "metadata": {}}, {"cell_type": "code", "source": "# Initialize AI Service function locally\nfrom ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\nstreaming = False\nfindex = 1 if streaming else 0\nlocal_function = gen_ai_service(context, vector_index_id=vector_index_id, space_id=space_id)[findex]\nmessages = []", "metadata": {"id": "ad1842a1-1083-4151-bcb9-361657fcef38"}, "outputs": [], "execution_count": 11}, {"cell_type": "code", "source": "local_question = \"Change this question to test your function\"\n\nmessages.append({ \"role\" : \"user\", \"content\": local_question })\n\ncontext = RuntimeContext(api_client=client, request_payload_json={\"messages\": messages})\n\nresponse = local_function(context)\n\nresult = ''\n\nif (streaming):\n    for chunk in response:\n        print(chunk, end=\"\\n\\n\", flush=True)\nelse:\n    print(response)\n", "metadata": {"id": "89fb7816-06c8-4e34-bd20-f82b5d3545ef"}, "outputs": [{"name": "stdout", "text": "{'headers': {'Content-Type': 'application/json'}, 'body': {'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'It seems like you\\'re asking for a change to a question, but you haven\\'t provided the original question. However, I can create a new question based on the career information you\\'ve provided:\\n\\n\"Which career path, between Software Engineer, Data Scientist, Digital Marketing Specialist, UX/UI Designer, Mechanical Engineer, Cloud Architect, Psychologist, or Chartered Accountant, aligns best with your interests and skills, considering the required skills, suggested degrees, top industries, and future trends for each role?\"'}}]}}\n", "output_type": "stream"}], "execution_count": 12}, {"cell_type": "markdown", "source": "## 3. Store and deploy the AI Service\nBefore you can deploy the AI Service, you must store the AI service in your watsonx.ai repository.", "metadata": {}}, {"cell_type": "code", "source": "# Look up software specification for the AI service\nsoftware_spec_id_in_project = \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\"\nsoftware_spec_id = \"\"\n\ntry:\n    software_spec_id = client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\nexcept:\n    software_spec_id = client.spaces.promote(software_spec_id_in_project, source_project_id, space_id)", "metadata": {"id": "234fd549-6f14-4c42-8d47-6b79e7afd39b"}, "outputs": [], "execution_count": 13}, {"cell_type": "code", "source": "# Define the request and response schemas for the AI service\nrequest_schema = {\n    \"application/json\": {\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"messages\": {\n                \"title\": \"The messages for this chat session.\",\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"role\": {\n                            \"title\": \"The role of the message author.\",\n                            \"type\": \"string\",\n                            \"enum\": [\"user\",\"assistant\"]\n                        },\n                        \"content\": {\n                            \"title\": \"The contents of the message.\",\n                            \"type\": \"string\"\n                        }\n                    },\n                    \"required\": [\"role\",\"content\"]\n                }\n            }\n        },\n        \"required\": [\"messages\"]\n    }\n}\n\nresponse_schema = {\n    \"application/json\": {\n        \"oneOf\": [{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service_stream\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices.\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"title\":\"The index of this result.\"},\"delta\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"content\":{\"description\":\"The contents of the message.\",\"type\":\"string\"},\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]},{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"description\":\"The index of this result.\"},\"message\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"},\"content\":{\"title\":\"Message content.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]}]\n    }\n}", "metadata": {"id": "363c7041-60bc-4b9e-a0bc-0d0741def5b8"}, "outputs": [], "execution_count": 14}, {"cell_type": "code", "source": "# Store the AI service in the repository\nai_service_metadata = {\n    client.repository.AIServiceMetaNames.NAME: \"Agentic-career-counsellor\",\n    client.repository.AIServiceMetaNames.DESCRIPTION: \"\",\n    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_spec_id,\n    client.repository.AIServiceMetaNames.CUSTOM: {},\n    client.repository.AIServiceMetaNames.REQUEST_DOCUMENTATION: request_schema,\n    client.repository.AIServiceMetaNames.RESPONSE_DOCUMENTATION: response_schema,\n    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n}\n\nai_service_details = client.repository.store_ai_service(meta_props=ai_service_metadata, ai_service=gen_ai_service)", "metadata": {"id": "672b956f-c4e3-4424-8c10-139676fe9eb5"}, "outputs": [], "execution_count": 15}, {"cell_type": "code", "source": "# Get the AI Service ID\n\nai_service_id = client.repository.get_ai_service_id(ai_service_details)", "metadata": {"id": "dd40b422-5c15-422d-8010-de5abe8113e6"}, "outputs": [], "execution_count": 16}, {"cell_type": "code", "source": "# Deploy the stored AI Service\ndeployment_custom = {\n    \"avatar_icon\": \"Bot\",\n    \"avatar_color\": \"background\",\n    \"placeholder_image\": \"placeholder2.png\"\n}\ndeployment_metadata = {\n    client.deployments.ConfigurationMetaNames.NAME: \"Agentic-career-counsellor\",\n    client.deployments.ConfigurationMetaNames.ONLINE: {},\n    client.deployments.ConfigurationMetaNames.CUSTOM: deployment_custom,\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Welcome! I assist students about their career. monitor their interest and give career suggestions\",\n    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n}\n\nfunction_deployment_details = client.deployments.create(ai_service_id, meta_props=deployment_metadata, space_id=space_id)\n", "metadata": {"id": "b46d375b-9bbf-4a2d-86c0-503ab374fce4"}, "outputs": [{"name": "stdout", "text": "\n\n######################################################################################\n\nSynchronous deployment creation for id: 'c20ef495-9c43-4664-aab8-e78f3a9dfbc9' started\n\n######################################################################################\n\n\ninitializing\nNote: online_url and serving_urls are deprecated and will be removed in a future release. Use inference instead.\n.....\nready\n\n\n-----------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_id='98839cde-e017-4563-b993-8803ead7ef8c'\n-----------------------------------------------------------------------------------------------\n\n\n", "output_type": "stream"}], "execution_count": 17}, {"cell_type": "markdown", "source": "## 4. Test AI Service", "metadata": {}}, {"cell_type": "code", "source": "# Get the ID of the AI Service deployment just created\n\ndeployment_id = client.deployments.get_id(function_deployment_details)\nprint(deployment_id)", "metadata": {"id": "72d5e7d7-0cdd-4fe1-9882-8198372755d6"}, "outputs": [{"name": "stdout", "text": "98839cde-e017-4563-b993-8803ead7ef8c\n", "output_type": "stream"}], "execution_count": 18}, {"cell_type": "code", "source": "messages = []\nremote_question = \"What skills should I learn for a career in AI?\"\nmessages.append({ \"role\" : \"user\", \"content\": remote_question })\npayload = { \"messages\": messages }", "metadata": {"id": "0af625eb-5863-48f3-a2a9-8ea24b5b49ec"}, "outputs": [], "execution_count": 19}, {"cell_type": "code", "source": "result = client.deployments.run_ai_service(deployment_id, payload)\nif \"error\" in result:\n    print(result[\"error\"])\nelse:\n    print(result)", "metadata": {"id": "22b5b453-1996-4eb7-9427-4ee81369f99d"}, "outputs": [{"name": "stdout", "text": "{'choices': [{'index': 0, 'message': {'content': 'To pursue a career in Artificial Intelligence (AI), you should focus on developing a combination of technical and soft skills. Here are some key areas to consider:\\n\\n1. **Programming**: Proficiency in languages such as Python, Java, or C++ is essential. Python is particularly popular in the AI community due to its simplicity and the availability of AI-specific libraries.\\n\\n2. **Mathematics**: A strong foundation in linear algebra, calculus, probability, and statistics is crucial for understanding and implementing AI algorithms.\\n\\n3. **Machine Learning**: Familiarize yourself with machine learning concepts and algorithms, including supervised and unsupervised learning, reinforcement learning, and neural networks.\\n\\n4. **Deep Learning Frameworks**: Gain expertise in deep learning frameworks like TensorFlow or PyTorch, which are widely used for building and training neural networks.\\n\\n5. **Data Modeling**: Learn how to clean, analyze, and visualize data using tools like Pandas, NumPy, and Matplotlib.\\n\\n6. **Natural Language Processing (NLP)**: As AI is increasingly applied to text and speech, understanding NLP concepts and tools like NLTK or SpaCy can be beneficial.\\n\\n7. **Problem-Solving**: AI often involves tackling complex problems, so strong analytical and problem-solving skills are important.\\n\\n8. **Communication**: The ability to explain complex AI concepts to non-technical stakeholders is valuable, especially in roles involving collaboration with cross-functional teams.\\n\\n9. **Stay Updated**: The field of AI evolves rapidly, so continuous learning and staying informed about the latest research and tools is essential.\\n\\nFor more detailed insights, you can refer to recent articles and research papers available on platforms like arXiv or Google Scholar. Additionally, online courses and certifications from platforms like Coursera, edX, and Udacity can provide structured learning paths.\\n\\n[{\"arguments\": {\"query\": \"latest skills in demand for AI career\"}, \"name\": \"GoogleSearch\"}]', 'role': 'assistant'}}]}\n", "output_type": "stream"}], "execution_count": 20}, {"cell_type": "markdown", "source": "# Next steps\nYou successfully deployed and tested the AI Service! You can now view\nyour deployment and test it as a REST API endpoint.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  ", "metadata": {}}, {"cell_type": "code", "source": "", "metadata": {"id": "7818fcdc-0318-4737-9ac4-d7963614eabb"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "c186fa0c-e01e-469e-b621-16120ccbe356"}, "outputs": [], "execution_count": null}]}